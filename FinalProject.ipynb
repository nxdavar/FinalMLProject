{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e7e44f",
   "metadata": {},
   "source": [
    "# Final ML Project\n",
    "## Daniel Bernal, Raymond Vuong, Rohit Punjani, and Neal Davar \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a208641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "Total # of Outliers: \n",
      "21\n",
      "Number of data points before outlier removal: \n",
      "1460\n",
      "Number of data points before after outlier removal: \n",
      "1439\n",
      "b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/fd60dmln4nq615ms_jvbcyj40000gn/T/ipykernel_27248/666622852.py:104: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  test_norm = (test - test.min()) / (test.max() - test.min())\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:163\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[1;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/computation/expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    238\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/computation/expressions.py:128\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     result \u001b[39m=\u001b[39m _evaluate_standard(op, op_str, a, b)\n\u001b[1;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/computation/expressions.py:69\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     68\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 107\u001b[0m\n\u001b[1;32m    104\u001b[0m     test_norm \u001b[39m=\u001b[39m (test \u001b[39m-\u001b[39m test\u001b[39m.\u001b[39mmin()) \u001b[39m/\u001b[39m (test\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m test\u001b[39m.\u001b[39mmin())\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m train_norm, test_norm\n\u001b[0;32m--> 107\u001b[0m train_norm, test_norm \u001b[39m=\u001b[39m normalize_data(training, testing)\n\u001b[1;32m    110\u001b[0m \u001b[39m# TODO: use PCA to reduce overall dimensionality\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[39m# TODO: SMOTE for regression to manage class imbalances\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[39m# - Model III: SVM Regression\u001b[39;00m\n\u001b[1;32m    128\u001b[0m labels \u001b[39m=\u001b[39m train_norm[\u001b[39m'\u001b[39m\u001b[39mSalePrice\u001b[39m\u001b[39m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[13], line 104\u001b[0m, in \u001b[0;36mnormalize_data\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize_data\u001b[39m(train, test):\n\u001b[1;32m    102\u001b[0m     \u001b[39m# your code goes here\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     train_norm \u001b[39m=\u001b[39m (train \u001b[39m-\u001b[39m train\u001b[39m.\u001b[39mmin()) \u001b[39m/\u001b[39m (train\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m train\u001b[39m.\u001b[39mmin())\n\u001b[0;32m--> 104\u001b[0m     test_norm \u001b[39m=\u001b[39m (test \u001b[39m-\u001b[39;49m test\u001b[39m.\u001b[39;49mmin()) \u001b[39m/\u001b[39m (test\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m test\u001b[39m.\u001b[39mmin())\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m train_norm, test_norm\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/ops/common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     68\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/arraylike.py:108\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__sub__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__sub__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 108\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, operator\u001b[39m.\u001b[39;49msub)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/frame.py:6946\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6942\u001b[0m other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[axis],))\n\u001b[1;32m   6944\u001b[0m \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_FRAME(\u001b[39mself\u001b[39m, other, axis, flex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, level\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 6946\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch_frame_op(other, op, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   6947\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/frame.py:6985\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[0;34m(self, right, func, axis)\u001b[0m\n\u001b[1;32m   6979\u001b[0m     \u001b[39m# TODO: The previous assertion `assert right._indexed_same(self)`\u001b[39;00m\n\u001b[1;32m   6980\u001b[0m     \u001b[39m#  fails in cases with empty columns reached via\u001b[39;00m\n\u001b[1;32m   6981\u001b[0m     \u001b[39m#  _frame_arith_method_with_reindex\u001b[39;00m\n\u001b[1;32m   6982\u001b[0m \n\u001b[1;32m   6983\u001b[0m     \u001b[39m# TODO operate_blockwise expects a manager of the same type\u001b[39;00m\n\u001b[1;32m   6984\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 6985\u001b[0m         bm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49moperate_blockwise(\n\u001b[1;32m   6986\u001b[0m             \u001b[39m# error: Argument 1 to \"operate_blockwise\" of \"ArrayManager\" has\u001b[39;49;00m\n\u001b[1;32m   6987\u001b[0m             \u001b[39m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[1;32m   6988\u001b[0m             \u001b[39m# \"ArrayManager\"\u001b[39;49;00m\n\u001b[1;32m   6989\u001b[0m             \u001b[39m# error: Argument 1 to \"operate_blockwise\" of \"BlockManager\" has\u001b[39;49;00m\n\u001b[1;32m   6990\u001b[0m             \u001b[39m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[1;32m   6991\u001b[0m             \u001b[39m# \"BlockManager\"\u001b[39;49;00m\n\u001b[1;32m   6992\u001b[0m             right\u001b[39m.\u001b[39;49m_mgr,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   6993\u001b[0m             array_op,\n\u001b[1;32m   6994\u001b[0m         )\n\u001b[1;32m   6995\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(bm)\n\u001b[1;32m   6997\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(right, Series) \u001b[39mand\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   6998\u001b[0m     \u001b[39m# axis=1 means we want to operate row-by-row\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/internals/managers.py:1409\u001b[0m, in \u001b[0;36mBlockManager.operate_blockwise\u001b[0;34m(self, other, array_op)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moperate_blockwise\u001b[39m(\u001b[39mself\u001b[39m, other: BlockManager, array_op) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BlockManager:\n\u001b[1;32m   1406\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1407\u001b[0m \u001b[39m    Apply array_op blockwise with another (aligned) BlockManager.\u001b[39;00m\n\u001b[1;32m   1408\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1409\u001b[0m     \u001b[39mreturn\u001b[39;00m operate_blockwise(\u001b[39mself\u001b[39;49m, other, array_op)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/internals/ops.py:63\u001b[0m, in \u001b[0;36moperate_blockwise\u001b[0;34m(left, right, array_op)\u001b[0m\n\u001b[1;32m     61\u001b[0m res_blks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[1;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m lvals, rvals, locs, left_ea, right_ea, rblk \u001b[39min\u001b[39;00m _iter_block_pairs(left, right):\n\u001b[0;32m---> 63\u001b[0m     res_values \u001b[39m=\u001b[39m array_op(lvals, rvals)\n\u001b[1;32m     64\u001b[0m     \u001b[39mif\u001b[39;00m left_ea \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m right_ea \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(res_values, \u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     65\u001b[0m         res_values \u001b[39m=\u001b[39m res_values\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:222\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[39m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m--> 222\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)\n\u001b[1;32m    224\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:170\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    166\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m         result \u001b[39m=\u001b[39m _masked_arith_op(left, right, op)\n\u001b[1;32m    171\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/machine-learning/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:108\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[39m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m--> 108\u001b[0m         result[mask] \u001b[39m=\u001b[39m op(xrav[mask], yrav[mask])\n\u001b[1;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training = pd.read_csv(\"train.csv\")\n",
    "testing = pd.read_csv(\"housing_testing.csv\")\n",
    "\n",
    "IL_F_ITERATIONS = 50\n",
    "\n",
    "print(len(training))\n",
    "\n",
    "# 1. Data Cleaning:\n",
    "\n",
    "training.drop('Id', axis=1, inplace=True)\n",
    "# fillna on the basis of whether MasVnrArea, LotFrontage, or any other categorical feature with na values\n",
    "training['MasVnrArea'].fillna(0, inplace=True)\n",
    "training['LotFrontage'].fillna(0, inplace=True)\n",
    "training['GarageYrBlt'].fillna(training['GarageYrBlt'].mean(), inplace=True)\n",
    "training.fillna('None', inplace=True)\n",
    "\n",
    "# drop duplicates:\n",
    "training.drop_duplicates(keep=False, inplace=True)\n",
    "\n",
    "# one hot encoding categorical variables:\n",
    "training = pd.get_dummies(training, columns=['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition'], drop_first=True)\n",
    "\n",
    "\n",
    "# use isolation forests to find potential outliers:\n",
    "freq_outlier_map = {} \n",
    "for i in range(0, IL_F_ITERATIONS):\n",
    "    anomalies = IsolationForest().fit_predict(training, 0.5)\n",
    "    training['anomalies'] = anomalies\n",
    "    outlier_indices = training.loc[training['anomalies'] == -1].index\n",
    "    # add outlier freqs to map\n",
    "    for j in range(0, len(outlier_indices)):\n",
    "        count = 0\n",
    "        if outlier_indices[j] in freq_outlier_map: \n",
    "            count = freq_outlier_map[outlier_indices[j]]\n",
    "        freq_outlier_map[outlier_indices[j]] = count + 1\n",
    "    \n",
    "    inlier_indices = training.loc[training['anomalies'] == 1].index\n",
    "\n",
    "    \n",
    "# drop outliers that are detected as anomalies more than 10% of the time\n",
    "final_outlier_indices = []\n",
    "print('Total # of Outliers: ')\n",
    "for outlier_index in freq_outlier_map.keys(): \n",
    "    if freq_outlier_map[outlier_index] > (0.10 * IL_F_ITERATIONS):\n",
    "        final_outlier_indices.append(outlier_index)\n",
    "print(len(final_outlier_indices))\n",
    "print('Number of data points before outlier removal: ')\n",
    "print(len(training))\n",
    "training.drop(index=final_outlier_indices, inplace=True)\n",
    "print('Number of data points before after outlier removal: ')\n",
    "print(len(training))\n",
    "\n",
    "\n",
    "# Anomaly Detection post PCA:\n",
    "\n",
    "\n",
    "# 2. Data Exploration: \n",
    "\n",
    "\n",
    "\n",
    "# 3. Feature Engineering:\n",
    "\n",
    "\n",
    "# consolidate bathroom columns into one col:\n",
    "training['TotalBathrooms'] = \\\n",
    "        training['FullBath'] + (0.5 * training['HalfBath']) + \\\n",
    "        training['BsmtFullBath'] + (0.5 * training['BsmtHalfBath'])\n",
    "\n",
    "print('b')        \n",
    "\n",
    "training.drop(['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath'], axis=1)\n",
    "\n",
    "# consolidate porch area into one column\n",
    "training['TotalPorchSF'] = \\\n",
    "        training['OpenPorchSF'] + training['EnclosedPorch'] + \\\n",
    "        training['3SsnPorch'] + training['ScreenPorch']\n",
    "    \n",
    "training.drop(['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', '3SsnPorch'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: scale the data \n",
    "def normalize_data(train, test):\n",
    "    # your code goes here\n",
    "    train_norm = (train - train.min()) / (train.max() - train.min())\n",
    "    test_norm = (test - test.min()) / (test.max() - test.min())\n",
    "    return train_norm, test_norm\n",
    "\n",
    "train_norm, test_norm = normalize_data(training, testing)\n",
    "\n",
    "\n",
    "# TODO: use PCA to reduce overall dimensionality\n",
    "\n",
    "# TODO: SMOTE for regression to manage class imbalances\n",
    "\n",
    "\n",
    "\n",
    "# 3. Modeling: 4 different type of regression models with cross validation:\n",
    "\n",
    "# - Model I: Linear Regression\n",
    "\n",
    "# - Model II: Regression Tree (Nonlinear Regression)\n",
    "\n",
    "# - Model III: SVM Regression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labels = train_norm['SalePrice']\n",
    "labels.values.ravel()\n",
    "features = train_norm.drop('SalePrice', axis = 1)\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(features.head())\n",
    "print(labels.head())\n",
    "\n",
    "\n",
    "linReg = LinearRegression()\n",
    "scores = cross_val_score(linReg, features, labels, cv=10)\n",
    "print(\"Accuracy:\", scores.mean()*100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b2edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129549a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c66eea1c4c7bb61b575e87dc258962edfd54bd0f6a298796fe44c73819b6ab09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

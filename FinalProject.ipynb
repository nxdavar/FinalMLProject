{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "62e7e44f",
         "metadata": {},
         "source": [
            "# Final ML Project\n",
            "## Daniel Bernal, Raymond Vuong, Rohit Punjani, and Neal Davar \n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d6fc9109",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "3e4c0104",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "id": "a208641d",
         "metadata": {},
         "outputs": [],
         "source": [
            "# import statements\n",
            "\n",
            "from sklearn.model_selection import cross_val_score\n",
            "from sklearn.model_selection import GridSearchCV\n",
            "import sklearn.metrics as metrics\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "from sklearn import preprocessing\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.metrics import accuracy_score\n",
            "from sklearn.metrics import confusion_matrix\n",
            "from sklearn.ensemble import IsolationForest\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.tree import DecisionTreeRegressor\n",
            "from sklearn.preprocessing import OneHotEncoder\n",
            "from sklearn.compose import ColumnTransformer\n",
            "from sklearn.neighbors import KNeighborsRegressor\n",
            "from sklearn.ensemble import RandomForestRegressor\n",
            "from sklearn.ensemble import GradientBoostingRegressor\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "id": "c6d64130",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Constants and other global variables: \n",
            "\n",
            "IL_F_ITERATIONS = 50"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "58fa4c94",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "0e9fb7a0",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "id": "7d9dd670",
         "metadata": {},
         "outputs": [],
         "source": [
            "# clean data by dropping cols like Id, imputing value\n",
            "# depending on the feature, and dropping duplicates:\n",
            "def clean_data(training): \n",
            "    training.drop('Id', axis=1, inplace=True)\n",
            "    # print(training.shape)\n",
            "    # training.head()\n",
            "    null_counts = training.isnull().sum()\n",
            "    missing_features = null_counts[null_counts > 0]\n",
            "    print(missing_features)\n",
            "    \n",
            "    \n",
            "    # grab all the numeric features and plot histograms\n",
            "    numeric_feats = training.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64'])\n",
            "    # TODO: UNCOMMENT THIS BEFORE SUBMISSION!\n",
            "    # for i in numeric_feats.columns:\n",
            "    #     plt.hist(numeric_feats[i])\n",
            "    #     plt.title(i)\n",
            "    #     plt.show()\n",
            "        \n",
            "    # fillna on the basis of whether MasVnrArea, LotFrontage, or any other categorical feature with na values\n",
            "    training['MasVnrArea'].fillna(0, inplace=True)\n",
            "    training['LotFrontage'].fillna(0, inplace=True)\n",
            "    training['GarageYrBlt'].fillna(training['GarageYrBlt'].mean(), inplace=True)\n",
            "    training.fillna('None', inplace=True)\n",
            "\n",
            "    # drop duplicates:\n",
            "    training.drop_duplicates(keep=False, inplace=True)\n",
            "\n",
            "    # plot correlation between features: \n",
            "    corr_mat = training.corr()\n",
            "    plt.subplots(figsize=(12, 9))\n",
            "    sns.heatmap(corr_mat, square=True)\n",
            "\n",
            "    # Changing categorial features to be stored as string\n",
            "    training['MSSubClass'] = training['MSSubClass'].astype(str)\n",
            "\n",
            "    # one hot encode:\n",
            "    ohe_col_list = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
            "                    'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']   \n",
            "    \n",
            "    dataset_dropped = pd.get_dummies(data=training, columns=ohe_col_list, drop_first=True)\n",
            "\n",
            "\n",
            "    return dataset_dropped"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "id": "96d7c6e5",
         "metadata": {},
         "outputs": [],
         "source": [
            "# TODO: ASK ANSHUL!!\n",
            "def one_hot_encoder(training, testing):\n",
            "   \n",
            "    ohe = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
            "    labels = training['SalePrice']\n",
            "    training_features = training.drop('SalePrice', axis=1)\n",
            "    ohe.fit(training_features)\n",
            "    transform_training = pd.DataFrame(ohe.transform(training_features).toarray())\n",
            "    print(ohe.get_feature_names_out())\n",
            "    transform_testing = pd.DataFrame(ohe.transform(testing).toarray())\n",
            "\n",
            "    pd.concat([transform_training, labels], axis=1)\n",
            "\n",
            "    print(transform_training)\n",
            "    print(transform_testing)\n",
            "\n",
            "    return transform_training, transform_testing\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "id": "1e57f786",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Uses the isolation forest technique to find outliers across 50 iterations\n",
            "# and removes records that are recorded as outliers > 10% of the time\n",
            "def run_isolation_forest(training):\n",
            "    # use isolation forests to find potential outliers:\n",
            "    freq_outlier_map = {} \n",
            "    for i in range(0, IL_F_ITERATIONS):\n",
            "        anomalies = IsolationForest().fit_predict(training, 0.5)\n",
            "        training['anomalies'] = anomalies\n",
            "        outlier_indices = training.loc[training['anomalies'] == -1].index\n",
            "        # add outlier freqs to map\n",
            "        for j in range(0, len(outlier_indices)):\n",
            "            count = 0\n",
            "            if outlier_indices[j] in freq_outlier_map: \n",
            "                count = freq_outlier_map[outlier_indices[j]]\n",
            "            freq_outlier_map[outlier_indices[j]] = count + 1\n",
            "        \n",
            "        inlier_indices = training.loc[training['anomalies'] == 1].index\n",
            "        \n",
            "\n",
            "        \n",
            "    # drop outliers that are detected as anomalies more than 10% of the time\n",
            "    final_outlier_indices = []\n",
            "    print('Total # of Outliers: ')\n",
            "    for outlier_index in freq_outlier_map.keys(): \n",
            "        if freq_outlier_map[outlier_index] > (0.10 * IL_F_ITERATIONS):\n",
            "            final_outlier_indices.append(outlier_index)\n",
            "    print(len(final_outlier_indices))\n",
            "    print('Number of data points before outlier removal: ')\n",
            "    print(len(training))\n",
            "    training.drop(index=final_outlier_indices, inplace=True)\n",
            "    print('Number of data points before after outlier removal: ')\n",
            "    print(len(training))\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "id": "8a21aeb6",
         "metadata": {},
         "outputs": [],
         "source": [
            "# function that normalizes the training and testing data:\n",
            "def normalize_data(train, test):\n",
            "    # your code goes here\n",
            "    train_norm = (train - train.min()) / (train.max() - train.min())\n",
            "    test_norm = (test - test.min()) / (test.max() - test.min())\n",
            "    return train_norm, test_norm"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "467b2edb",
         "metadata": {},
         "outputs": [],
         "source": [
            "# performs feature engineering by consolidating features,\n",
            "# dropping unnecessary features, and more\n",
            "def feature_engineering(training, testing):\n",
            "    # consolidate bathroom columns into one col:\n",
            "    training['TotalBathrooms'] = \\\n",
            "        training['FullBath'] + (0.5 * training['HalfBath']) + \\\n",
            "        training['BsmtFullBath'] + (0.5 * training['BsmtHalfBath'])\n",
            "\n",
            "\n",
            "    training.drop(['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath'], axis=1)\n",
            "\n",
            "    # consolidate porch area into one column\n",
            "    training['TotalPorchSF'] = training['OpenPorchSF'] + \\\n",
            "        training['EnclosedPorch'] + \\\n",
            "        training['3SsnPorch'] + training['ScreenPorch']\n",
            "\n",
            "    training.drop(['OpenPorchSF', 'EnclosedPorch',\n",
            "                '3SsnPorch', '3SsnPorch'], axis=1)\n",
            "\n",
            " "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "30a1cafe",
         "metadata": {},
         "outputs": [],
         "source": [
            "# Run Decision Tree Regression on our Data: \n",
            "def do_decision_tree_regression(training):\n",
            "  labels = training['SalePrice']\n",
            "  features = training.drop('SalePrice', axis=1)\n",
            "  x_train, x_test, y_train, y_test = train_test_split(\n",
            "      features, labels, test_size=0.20)\n",
            "  dt = DecisionTreeRegressor(random_state=2)\n",
            "  dt.fit(x_train, y_train)\n",
            "  # Prediction = np.zeros((len(y_test), 1))\n",
            "  Prediction = dt.predict(x_test)\n",
            "  print(\"R2 Score No Crossval\")\n",
            "  print(metrics.r2_score(y_test, Prediction))\n",
            "  print(\"MSE\")\n",
            "  print(metrics.mean_squared_error(y_test, Prediction))\n",
            "\n",
            "  #outerloop of crossval\n",
            "  cv = cross_val_score(dt, features, labels, cv=10)\n",
            "  r2 = sum(cv) / cv.size\n",
            "  # print(r2)\n",
            "  #innerloop of crossval\n",
            "  parameters = {'max_depth': [5, 10, 15, 20, 30, 40], 'min_samples_leaf': [\n",
            "      5, 10, 15, 20, 30, 40], 'max_features': [5, 10, 15, 30, 40]}\n",
            "  grid = GridSearchCV(DecisionTreeRegressor(),\n",
            "                      param_grid=parameters, cv=10, scoring='r2')\n",
            "  grid.fit(features, labels)\n",
            "  print(\"Best parameters\")\n",
            "  print(grid.best_params_)\n",
            "  # print(grid.best_score_)\n",
            "\n",
            "  #combined\n",
            "  cv = cross_val_score(grid, features, labels, cv=5)\n",
            "  r2 = sum(cv)/cv.size\n",
            "  print(\"R2 with cross val\")\n",
            "  print(r2)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "717907ee",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "34f1f17f",
         "metadata": {},
         "outputs": [],
         "source": [
            "# KNN Regression Model Implementation: \n",
            "#KNN regression\n",
            "def do_KNN_regression(training):\n",
            "  labels = training['SalePrice']\n",
            "  features = training.drop('SalePrice', axis=1)\n",
            "  x_train, x_test, y_train, y_test = train_test_split(\n",
            "      features, labels, test_size=0.20)\n",
            "  dt = KNeighborsRegressor()\n",
            "  dt.fit(x_train, y_train)\n",
            "  # Prediction = np.zeros((len(y_test), 1))\n",
            "  Prediction = dt.predict(x_test)\n",
            "  print(\"R2 Score No Crossval\")\n",
            "  print(metrics.r2_score(y_test, Prediction))\n",
            "  print(\"MSE\")\n",
            "  print(metrics.mean_squared_error(y_test, Prediction))\n",
            "\n",
            "  #outerloop of crossval\n",
            "  cv = cross_val_score(dt, features, labels, cv=10)\n",
            "  r2 = sum(cv) / cv.size\n",
            "  # print(r2)\n",
            "  #innerloop of crossval\n",
            "  parameters = {'n_neighbors': [5, 10, 15, 20, 30, 40]}\n",
            "  grid = GridSearchCV(KNeighborsRegressor(),\n",
            "                      param_grid=parameters, cv=10, scoring='r2')\n",
            "  grid.fit(features, labels)\n",
            "  print(\"Best parameters\")\n",
            "  print(grid.best_params_)\n",
            "  # print(grid.best_score_)\n",
            "\n",
            "  #combined\n",
            "  cv = cross_val_score(grid, features, labels, cv=5)\n",
            "  r2 = sum(cv)/cv.size\n",
            "  print(\"R2 with cross val\")\n",
            "  print(r2)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "41192d54",
         "metadata": {},
         "outputs": [],
         "source": [
            "# run a linear regression model \n",
            "def runLinReg(train_norm):\n",
            "    labels = train_norm['SalePrice']\n",
            "    labels.values.ravel()\n",
            "    features = train_norm.drop('SalePrice', axis=1)\n",
            "    print(features.shape)\n",
            "    print(labels.shape)\n",
            "    print(features.head())\n",
            "    print(labels.head())\n",
            "\n",
            "\n",
            "    linReg = LinearRegression()\n",
            "    scores = cross_val_score(linReg, features, labels, cv=10)\n",
            "    print(\"Accuracy:\", scores.mean()*100)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 35,
         "id": "129549a1",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "LotFrontage      259\n",
                  "Alley           1369\n",
                  "MasVnrType         8\n",
                  "MasVnrArea         8\n",
                  "BsmtQual          37\n",
                  "BsmtCond          37\n",
                  "BsmtExposure      38\n",
                  "BsmtFinType1      37\n",
                  "BsmtFinType2      38\n",
                  "Electrical         1\n",
                  "FireplaceQu      690\n",
                  "GarageType        81\n",
                  "GarageYrBlt       81\n",
                  "GarageFinish      81\n",
                  "GarageQual        81\n",
                  "GarageCond        81\n",
                  "PoolQC          1453\n",
                  "Fence           1179\n",
                  "MiscFeature     1406\n",
                  "dtype: int64\n",
                  "MSZoning           4\n",
                  "LotFrontage      227\n",
                  "Alley           1352\n",
                  "Utilities          2\n",
                  "Exterior1st        1\n",
                  "Exterior2nd        1\n",
                  "MasVnrType        16\n",
                  "MasVnrArea        15\n",
                  "BsmtQual          44\n",
                  "BsmtCond          45\n",
                  "BsmtExposure      44\n",
                  "BsmtFinType1      42\n",
                  "BsmtFinSF1         1\n",
                  "BsmtFinType2      42\n",
                  "BsmtFinSF2         1\n",
                  "BsmtUnfSF          1\n",
                  "TotalBsmtSF        1\n",
                  "BsmtFullBath       2\n",
                  "BsmtHalfBath       2\n",
                  "KitchenQual        1\n",
                  "Functional         2\n",
                  "FireplaceQu      730\n",
                  "GarageType        76\n",
                  "GarageYrBlt       78\n",
                  "GarageFinish      78\n",
                  "GarageCars         1\n",
                  "GarageArea         1\n",
                  "GarageQual        78\n",
                  "GarageCond        78\n",
                  "PoolQC          1456\n",
                  "Fence           1169\n",
                  "MiscFeature     1408\n",
                  "SaleType           1\n",
                  "dtype: int64\n",
                  "(1459, 235)\n",
                  "(1460, 238)\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/var/folders/wg/fd60dmln4nq615ms_jvbcyj40000gn/T/ipykernel_30292/2977189836.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
                  "  test_norm = (test - test.min()) / (test.max() - test.min())\n",
                  "/var/folders/wg/fd60dmln4nq615ms_jvbcyj40000gn/T/ipykernel_30292/2977189836.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
                  "  test_norm = (test - test.min()) / (test.max() - test.min())\n",
                  "/var/folders/wg/fd60dmln4nq615ms_jvbcyj40000gn/T/ipykernel_30292/2977189836.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
                  "  test_norm = (test - test.min()) / (test.max() - test.min())\n"
               ]
            }
         ],
         "source": [
            "\n",
            "training = pd.read_csv(\"train.csv\")\n",
            "testing = pd.read_csv(\"housing_testing.csv\")\n",
            "\n",
            "\n",
            "\n",
            "# 1. Data Cleaning\n",
            "training = clean_data(training)\n",
            "testing = clean_data(testing)\n",
            "\n",
            "\n",
            "\n",
            "# one_hot_encoder(training, testing)\n",
            "\n",
            "#2. Data Cleaning Pt. 2\n",
            "# run_isolation_forest(training)\n",
            "# print(training.dtypes)\n",
            "# print(testing.dtypes)\n",
            "# 2. Normalization\n",
            "train_norm, test_norm = normalize_data(training, testing)\n",
            "\n",
            "numerics =  ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
            "testing_select = testing.select_dtypes(exclude=numerics)\n",
            "\n",
            "\n",
            "training_select = training.select_dtypes(exclude=numerics)\n",
            "\n",
            "print(testing_select.shape)\n",
            "print(training_select.shape)\n",
            "\n",
            "# print(training.head)\n",
            "# print(testing.head)\n",
            "\n",
            "\n",
            "\n",
            "# #3. Data Exploration: \n",
            "\n",
            "\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "2b4100f2",
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.9"
      },
      "vscode": {
         "interpreter": {
            "hash": "c66eea1c4c7bb61b575e87dc258962edfd54bd0f6a298796fe44c73819b6ab09"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}

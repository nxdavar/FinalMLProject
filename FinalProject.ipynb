{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e7e44f",
   "metadata": {},
   "source": [
    "# Final ML Project\n",
    "## Daniel Bernal, Raymond Vuong, Rohit Punjani, and Neal Davar \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "Total # of Outliers: \n",
      "19\n",
      "Number of data points before outlier removal: \n",
      "1460\n",
      "Number of data points before after outlier removal: \n",
      "1441\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training = pd.read_csv(\"train.csv\")\n",
    "\n",
    "IL_F_ITERATIONS = 50\n",
    "\n",
    "print(len(training))\n",
    "\n",
    "# 1. Data Cleaning:\n",
    "\n",
    "training.drop('Id', axis=1, inplace=True)\n",
    "# fillna on the basis of whether MasVnrArea, LotFrontage, or any other categorical feature with na values\n",
    "training['MasVnrArea'].fillna(0, inplace=True)\n",
    "training['LotFrontage'].fillna(0, inplace=True)\n",
    "training['GarageYrBlt'].fillna(training['GarageYrBlt'].mean(), inplace=True)\n",
    "training.fillna('None', inplace=True)\n",
    "\n",
    "# drop duplicates:\n",
    "training.drop_duplicates(keep=False, inplace=True)\n",
    "\n",
    "# one hot encoding categorical variables:\n",
    "training = pd.get_dummies(training, columns=['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition'], drop_first=True)\n",
    "\n",
    "# use isolation forests to find potential outliers:\n",
    "freq_outlier_map = {} \n",
    "for i in range(0, IL_F_ITERATIONS):\n",
    "    anomalies = IsolationForest().fit_predict(training, 0.5)\n",
    "    training['anomalies'] = anomalies\n",
    "    outlier_indices = training.loc[training['anomalies'] == -1].index\n",
    "    # add outlier freqs to map\n",
    "    for j in range(0, len(outlier_indices)):\n",
    "        count = 0\n",
    "        if outlier_indices[j] in freq_outlier_map: \n",
    "            count = freq_outlier_map[outlier_indices[j]]\n",
    "        freq_outlier_map[outlier_indices[j]] = count + 1\n",
    "    \n",
    "    inlier_indices = training.loc[training['anomalies'] == 1].index\n",
    "\n",
    "    \n",
    "# drop outliers that are detected as anomalies more than 10% of the time\n",
    "final_outlier_indices = []\n",
    "print('Total # of Outliers: ')\n",
    "for outlier_index in freq_outlier_map.keys(): \n",
    "    if freq_outlier_map[outlier_index] > (0.10 * IL_F_ITERATIONS):\n",
    "        final_outlier_indices.append(outlier_index)\n",
    "print(len(final_outlier_indices))\n",
    "print('Number of data points before outlier removal: ')\n",
    "print(len(training))\n",
    "training.drop(index=final_outlier_indices, inplace=True)\n",
    "print('Number of data points before after outlier removal: ')\n",
    "print(len(training))\n",
    "\n",
    "\n",
    "# Anomaly Detection post PCA:\n",
    "\n",
    "\n",
    "# 2. Data Exploration: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Feature Engineering:\n",
    "\n",
    "\n",
    "# consolidate bathroom columns into one col:\n",
    "training['TotalBathrooms'] = \\\n",
    "        training['FullBath'] + (0.5 * training['HalfBath']) + \\\n",
    "        training['BsmtFullBath'] + (0.5 * training['BsmtHalfBath'])\n",
    "\n",
    "print('b')        \n",
    "\n",
    "training.drop(['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath'], axis=1)\n",
    "\n",
    "# consolidate porch area into one column\n",
    "training['TotalPorchSF'] = \\\n",
    "        training['OpenPorchSF'] + training['EnclosedPorch'] + \\\n",
    "        training['3SsnPorch'] + training['ScreenPorch']\n",
    "    \n",
    "training.drop(['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', '3SsnPorch'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: scale the data \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(training)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=training.columns\n",
    ")\n",
    "# TODO: use PCA to reduce overall dimensionality\n",
    "\n",
    "# TODO: SMOTE for regression to manage class imbalances\n",
    "\n",
    "# training.corr()['SalePrice'].sort_values(ascending=False).plot(kind='barh', figsize=(20,10))\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Modeling: 4 different type of regression models with cross validation:\n",
    "\n",
    "# - Model I: Linear Regression\n",
    "\n",
    "# - Model II: Regression Tree (Nonlinear Regression)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.20, random_state=10)\n",
    "\n",
    "print(\"X Train Length: \", len(x_train))\n",
    "print(\"X Test Length: \",len(x_test))\n",
    "print(\"Y Train Length: \",len(y_train))\n",
    "print(\"Y Test Length: \",len(y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b2edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129549a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c66eea1c4c7bb61b575e87dc258962edfd54bd0f6a298796fe44c73819b6ab09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
